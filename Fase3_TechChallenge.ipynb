{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1GcX6-bhXaC7ge8xxFtkP3JO4eGipl2-P",
      "authorship_tag": "ABX9TyPGDCA+GK7Za6Uhihl4LFew",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e53d14c21ad9463b889a41df114e60e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_313cad94dc5e46508245c9033803a492",
              "IPY_MODEL_30539a32f6384664943d37c4838c5c79",
              "IPY_MODEL_e95052d2d4e74ec8b5e6f424f2521c2b"
            ],
            "layout": "IPY_MODEL_6e73600409ad4d4cafc50e609d016b23"
          }
        },
        "313cad94dc5e46508245c9033803a492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_377a2fa8232e4f60a9b738144b42bb0b",
            "placeholder": "​",
            "style": "IPY_MODEL_058c613153da4eb1867671e035db1381",
            "value": "Map: 100%"
          }
        },
        "30539a32f6384664943d37c4838c5c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c76795b9eff74f57a7598f4d8cb9c1ee",
            "max": 15000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3b9959dc4e14fc98933c8e073b081b0",
            "value": 15000
          }
        },
        "e95052d2d4e74ec8b5e6f424f2521c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8ee4196d77c45868049583a40c55493",
            "placeholder": "​",
            "style": "IPY_MODEL_0e775820f99142f3b4fef130c14e56a0",
            "value": " 15000/15000 [00:16&lt;00:00, 887.75 examples/s]"
          }
        },
        "6e73600409ad4d4cafc50e609d016b23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "377a2fa8232e4f60a9b738144b42bb0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "058c613153da4eb1867671e035db1381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c76795b9eff74f57a7598f4d8cb9c1ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3b9959dc4e14fc98933c8e073b081b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8ee4196d77c45868049583a40c55493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e775820f99142f3b4fef130c14e56a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silviosnjr/Fase3_TechChallenge/blob/main/Fase3_TechChallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3ª fase do TechChallenge | Pos Tech | IA para Dev's\n",
        "## Silvio Sales do Nascimento Junior (RM 353303)"
      ],
      "metadata": {
        "id": "jxfc4LZRSikt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vídeo no Youtube sobre o TechChallenge [https://youtu.be/8c6EZHQRCeI](https://youtu.be/8c6EZHQRCeI)"
      ],
      "metadata": {
        "id": "CYEItMcmy0U6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conectando ao Google drive onde está o dataset"
      ],
      "metadata": {
        "id": "X6sr6JptTDDx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDM8IigtzEbZ",
        "outputId": "70b171df-e070-43be-dffa-2546fbd440a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando bibliotecas que podem ser necessárias"
      ],
      "metadata": {
        "id": "It-EcIfW2eTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install beautifulsoup4\n",
        "%pip install requests\n",
        "%pip install torch\n",
        "%pip install pandas\n",
        "%pip install scikit-learn\n",
        "%pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiEcG_fS1Yu_",
        "outputId": "00c2fafb-6d76-4f65-ef2b-81000debc116"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Escolha do Dataset\n",
        "Não foi possível fazer tratamento de uma base de dados tão extensa como a do `trn.json`. Por isso fiz uma extração da base de dados com 15 mil registro o arquivo está no [drive](https://drive.google.com/file/d/1a47o65lY_XsGDHY2ORaB75j0cB2-2WIX/view?usp=drive_link)."
      ],
      "metadata": {
        "id": "PZLbXgNs4VB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/Fase3_TechChallenge/dataset/trn_15k.json'"
      ],
      "metadata": {
        "id": "vVbfVSUU4Pe2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preparação do Dataset\n",
        "### 2.1 Carregar e visualizar os dados\n",
        "Carregando o arquivo trn15k.json para visualizá-lo e entender sua estrutura:"
      ],
      "metadata": {
        "id": "1Lvah6Ca6KPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar o arquivo JSON\n",
        "df = pd.read_json(file_path, lines=True)\n",
        "\n",
        "# Ver as primeiras linhas do dataset\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvWCjlmc6JZ6",
        "outputId": "c5401ed2-65e5-4c5a-d82d-4825504392c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0         Yellow Box Women's Yulisa Flip Flop Sandal   \n",
            "1                   Nine West Women's Eastnor Sandal   \n",
            "2  Roma Costume Women's 1 Piece Santa's Envy-Red ...   \n",
            "3  1 Box of 100 Sony 1.55v Silver Oxide Watch Bat...   \n",
            "4  Winning Angels: The 7 Fundamentals of Early St...   \n",
            "\n",
            "                                             content  \n",
            "0                                                     \n",
            "1                                                     \n",
            "2                                                     \n",
            "3  100 Sony 377 Watch Batteries Silver Oxide, Mer...  \n",
            "4  \"Winning Angels is a superbly organised and in...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Limpeza e pré-processamento dos dados\n",
        "Limpar e pré-processar os dados conforme necessário para o modelo escolhido."
      ],
      "metadata": {
        "id": "fHNvDv3m6rmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Função para limpeza do texto (remoção de caracteres especiais, conversão para minúsculas, etc.)\n",
        "def limpar_texto(texto):\n",
        "    texto = texto.lower()  # Converter para minúsculas\n",
        "    texto = re.sub(r'[^a-zA-Z0-9\\s]', '', texto)  # Remover caracteres especiais\n",
        "    texto = re.sub(r'\\s+', ' ', texto).strip()  # Remover espaços extras\n",
        "    return texto\n",
        "\n",
        "# Aplicar a limpeza nas colunas 'title' e 'content'\n",
        "df['title_clean'] = df['title'].apply(limpar_texto)\n",
        "df['content_clean'] = df['content'].apply(limpar_texto)\n",
        "\n",
        "# Visualizar os dados limpos\n",
        "print(df[['title_clean', 'content_clean']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHM6Fqwj7NOm",
        "outputId": "801fb91f-6773-4109-dc86-310dd5af4110"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         title_clean  \\\n",
            "0          yellow box womens yulisa flip flop sandal   \n",
            "1                    nine west womens eastnor sandal   \n",
            "2   roma costume womens 1 piece santas envyred white   \n",
            "3  1 box of 100 sony 155v silver oxide watch batt...   \n",
            "4  winning angels the 7 fundamentals of early sta...   \n",
            "\n",
            "                                       content_clean  \n",
            "0                                                     \n",
            "1                                                     \n",
            "2                                                     \n",
            "3  100 sony 377 watch batteries silver oxide merc...  \n",
            "4  winning angels is a superbly organised and inv...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Preparar os prompts para o fine-tuning"
      ],
      "metadata": {
        "id": "i6tXJjv_7W2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar prompts para o fine-tuning usando o título e o conteúdo\n",
        "df['prompt'] = 'Título: ' + df['title_clean'] + '\\nDescrição:'\n",
        "df['resposta'] = df['content_clean']\n",
        "\n",
        "# Exibir alguns prompts preparados\n",
        "print(df[['prompt', 'resposta']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tvd69lwc72c1",
        "outputId": "abfcca52-cbe4-4b23-d6f4-f8ceb3d94af2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              prompt  \\\n",
            "0  Título: yellow box womens yulisa flip flop san...   \n",
            "1  Título: nine west womens eastnor sandal\\nDescr...   \n",
            "2  Título: roma costume womens 1 piece santas env...   \n",
            "3  Título: 1 box of 100 sony 155v silver oxide wa...   \n",
            "4  Título: winning angels the 7 fundamentals of e...   \n",
            "\n",
            "                                            resposta  \n",
            "0                                                     \n",
            "1                                                     \n",
            "2                                                     \n",
            "3  100 sony 377 watch batteries silver oxide merc...  \n",
            "4  winning angels is a superbly organised and inv...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Chamada do Foundation Model\n",
        "### 3.1 Importando o modelo BERT pré-treinado:"
      ],
      "metadata": {
        "id": "yO465Z8d8yna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Carregar o tokenizer e o modelo pré-treinado BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# Definir dispositivo (GPU ou CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fY1p6Ig9KdL",
        "outputId": "c6393074-fad7-45b5-81f2-0b7d9844f467"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Rodar um teste com o modelo pré-treinado:"
      ],
      "metadata": {
        "id": "0Bv4y7hc9kj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para fazer o teste com o modelo pré-treinado\n",
        "def test_model_on_sample(prompt):\n",
        "    model.eval()  # Colocar o modelo em modo de avaliação\n",
        "    with torch.no_grad():\n",
        "        # Tokenizar o texto de exemplo\n",
        "        encoding = tokenizer(\n",
        "            prompt,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=128,\n",
        "            return_tensors='pt'\n",
        "        ).to(device)\n",
        "\n",
        "        # Fazer uma previsão com o modelo pré-treinado\n",
        "        outputs = model(**encoding)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        return predictions.item()\n",
        "\n",
        "# Testar o modelo com um exemplo do dataset\n",
        "prompt_exemplo = \"Title: Disney Pixar? \\nDescription: Disney Pixar\"\n",
        "resultado = test_model_on_sample(prompt_exemplo)\n",
        "\n",
        "print(\"Resultado da previsão antes do fine-tuning:\", resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8bzfiYs9q7R",
        "outputId": "b4b785ee-c2bd-4897-cdd9-63b57bc57f09"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado da previsão antes do fine-tuning: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Execução do Fine-Tuning\n"
      ],
      "metadata": {
        "id": "xDOPHhidAjMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "rCzvAEo-Cubj",
        "outputId": "ae184c25-8834-4e48-a686-da56e1087814"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.1 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              },
              "id": "492347b2864c42e79e03129b44a1fc39"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Função para tokenizar os prompts e adicionar rótulos\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['prompt'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "# Certifique-se de que você tem uma coluna de rótulos no seu dataframe, por exemplo, 'label'\n",
        "# Se os rótulos não existirem, você precisará adicioná-los de acordo com a sua tarefa de classificação.\n",
        "df['label'] = df['resposta'].apply(lambda x: 1 if \"relevante\" in x else 0)  # Exemplo de criação de rótulos\n",
        "\n",
        "# Converter o DataFrame para Dataset Hugging Face\n",
        "dataset = Dataset.from_pandas(df)\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Definir os parâmetros de treinamento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # Diretório para salvar os resultados\n",
        "    num_train_epochs=3,              # Número de épocas\n",
        "    per_device_train_batch_size=16,  # Tamanho do batch de treino\n",
        "    per_device_eval_batch_size=64,   # Tamanho do batch de avaliação\n",
        "    warmup_steps=500,                # Passos de aquecimento para o otimizador\n",
        "    weight_decay=0.01,               # Taxa de decaimento de peso para regularização\n",
        "    logging_dir='./logs',            # Diretório para salvar logs\n",
        "    logging_steps=10,                # Log a cada 10 passos\n",
        "    evaluation_strategy=\"epoch\"      # Avaliação no final de cada época\n",
        ")\n",
        "\n",
        "# Carregar o modelo pré-treinado BERT\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# Configurar o Trainer com rótulos\n",
        "trainer = Trainer(\n",
        "    model=model,                         # O modelo BERT a ser ajustado\n",
        "    args=training_args,                  # Parâmetros de treinamento definidos acima\n",
        "    train_dataset=dataset,               # Dataset de treino\n",
        "    eval_dataset=dataset,                # Dataset de avaliação (pode separar dados de validação se necessário)\n",
        ")\n",
        "\n",
        "# Executar o fine-tuning\n",
        "trainer.train()\n",
        "\n",
        "# Salvar o modelo ajustado\n",
        "model.save_pretrained(\"/content/drive/My Drive/Fase3_TechChallenge/fine_tuned_bert\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238,
          "referenced_widgets": [
            "e53d14c21ad9463b889a41df114e60e5",
            "313cad94dc5e46508245c9033803a492",
            "30539a32f6384664943d37c4838c5c79",
            "e95052d2d4e74ec8b5e6f424f2521c2b",
            "6e73600409ad4d4cafc50e609d016b23",
            "377a2fa8232e4f60a9b738144b42bb0b",
            "058c613153da4eb1867671e035db1381",
            "c76795b9eff74f57a7598f4d8cb9c1ee",
            "f3b9959dc4e14fc98933c8e073b081b0",
            "e8ee4196d77c45868049583a40c55493",
            "0e775820f99142f3b4fef130c14e56a0"
          ]
        },
        "id": "xJAJ6gVsD4y_",
        "outputId": "d4b260fd-b9ab-4c49-8bd5-46ec6fbb637c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e53d14c21ad9463b889a41df114e60e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2814' max='2814' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2814/2814 22:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Geração de Respostas\n",
        "Configure o modelo treinado para receber perguntas dos usuários. O modelo deverá gerar uma resposta baseada na pergunta do usuário e nos dados provenientes do _fine-tuning_, incluindo as fontes fornecidas."
      ],
      "metadata": {
        "id": "76GkfIbtP9UU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "\n",
        "# Carregar o dataset preparado\n",
        "file_path = '/content/drive/My Drive/Fase3_TechChallenge/dataset/trn_15k.json'\n",
        "df = pd.read_json(file_path, lines=True)\n",
        "\n",
        "# Carregar o modelo e o tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained(\"/content/drive/My Drive/Fase3_TechChallenge/fine_tuned_bert\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Colocar o modelo em modo de avaliação\n",
        "model.eval()\n",
        "\n",
        "# Função para buscar a informação mais relevante no dataset\n",
        "def buscar_resposta(pergunta):\n",
        "    # Tokenizar a pergunta do usuário\n",
        "    inputs = tokenizer(pergunta, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    # Fazer a previsão com o modelo fine-tuned\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Extrair a saída da previsão (logits)\n",
        "    logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # Procurar correspondências no dataset com base na pergunta\n",
        "    resultados = df[df['title'].str.contains(pergunta, case=False, na=False)]\n",
        "\n",
        "    if not resultados.empty:\n",
        "        # Retornar a descrição correspondente\n",
        "        return resultados.iloc[0]['content']  # Retorna o primeiro resultado encontrado\n",
        "    else:\n",
        "        return \"Desculpe, não consegui encontrar uma resposta relevante no dataset.\"\n",
        "\n",
        "# Exemplo de pergunta em inglês\n",
        "pergunta_usuario = \"Lord of the Rings?\"\n",
        "resposta = buscar_resposta(pergunta_usuario)\n",
        "\n",
        "# Exibir a resposta\n",
        "print(f\"Pergunta: {pergunta_usuario}\")\n",
        "print(f\"Resposta: {resposta}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2swqrg--L3Rt",
        "outputId": "4d377ae3-5083-4370-993f-2cda2836fce9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta: Lord of the Rings?\n",
            "Resposta: Ian Brodie is one of New Zealand's most successful non-fiction writers of recent years. The Lord of the Rings Location Guidebook was one of the inaugural Booksellers Platinum Bestsellers, with international sales of over 450,000 copies. Ian lives in Matamata where he is the Media and Communications Manager for Hobbiton Movie Set. He is also the author of the highly successful aviation series, Warbirds over Wanaka, and in 2005 he was awarded an MNZM for services to tourism. A devoted Tolkien fanatic, keen photographer and movie fan, he is currently working on another movie-related book.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pergunta_usuario = \"Brazil?\"\n",
        "resposta = buscar_resposta(pergunta_usuario)\n",
        "\n",
        "# Exibir a resposta\n",
        "print(f\"Pergunta: {pergunta_usuario}\")\n",
        "print(f\"Resposta: {resposta}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptK89mgjQfwH",
        "outputId": "8fbe28b3-e4eb-4373-e56c-fffd509ccbbe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta: Brazil?\n",
            "Resposta: This official 2014 FIFA World Cup wall chart has a complete list of team groups &amp;&nbsp;fixtures so that you can plot the tournament all the way to the final. This&nbsp;wall chart&nbsp;measures 61c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pergunta_usuario = \"iPhone?\"\n",
        "resposta = buscar_resposta(pergunta_usuario)\n",
        "\n",
        "# Exibir a resposta\n",
        "print(f\"Pergunta: {pergunta_usuario}\")\n",
        "print(f\"Resposta: {resposta}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT4-JXnWR8q9",
        "outputId": "db4917c6-93aa-433d-f285-18a4aa62b7d8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta: iPhone?\n",
            "Resposta: Shipped and sold by AccessoryOne!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pergunta_usuario = \"Samsung?\"\n",
        "resposta = buscar_resposta(pergunta_usuario)\n",
        "\n",
        "# Exibir a resposta\n",
        "print(f\"Pergunta: {pergunta_usuario}\")\n",
        "print(f\"Resposta: {resposta}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZx1FTQRxk4T",
        "outputId": "93f98e8b-06a8-4b56-ec75-de8c74195a7b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta: Samsung?\n",
            "Resposta: Ships by MoMo Store Packing from US. Usually takes 3-5 business days for delivery in US!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pergunta_usuario = \"FIAP\"\n",
        "resposta = buscar_resposta(pergunta_usuario)\n",
        "\n",
        "# Exibir a resposta\n",
        "print(f\"Pergunta: {pergunta_usuario}\")\n",
        "print(f\"Resposta: {resposta}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Wm-uGXtxqtA",
        "outputId": "3d88e2f4-634b-414b-ae00-6d09f80a7091"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta: FIAP\n",
            "Resposta: Desculpe, não consegui encontrar uma resposta relevante no dataset.\n"
          ]
        }
      ]
    }
  ]
}